CUDA_DEVICE_ORDER=PCI_BUS_ID CUDA_VISIBLE_DEVICES=2 python main.py  --use_mlt --mlt19_langs Korean --model_architecture vit_atienza --image_height 224 --tokenizer_name oda_giga_tokenizer --batch_size 128 --square_image_max_size 224 --loss_function ctc --num_workers_train 16 --epoches 75 --learning_rate 0.0001 --reduce_on_plateau 5 --decoder_architecture transformer --output_model_name non_linear_korean_from_hiertext --load_checkpoint --checkpoint_name /data/users/amolina/oda_ocr_output/non_linear_hiertext_only_base/non_linear_hiertext_only_base.pt
CUDA_DEVICE_ORDER=PCI_BUS_ID CUDA_VISIBLE_DEVICES=2 python main.py  --use_mlt --mlt19_langs Arabic --model_architecture vit_atienza --image_height 224 --tokenizer_name oda_giga_tokenizer --batch_size 128 --square_image_max_size 224 --loss_function ctc --num_workers_train 16 --epoches 75 --learning_rate 0.0001 --reduce_on_plateau 5 --decoder_architecture transformer --output_model_name non_linear_arabic_from_hiertext --load_checkpoint --checkpoint_name /data/users/amolina/oda_ocr_output/non_linear_hiertext_only_base/non_linear_hiertext_only_base.pt
CUDA_DEVICE_ORDER=PCI_BUS_ID CUDA_VISIBLE_DEVICES=2 python main.py  --use_mlt --mlt19_langs Latin --model_architecture vit_atienza --image_height 224 --tokenizer_name oda_giga_tokenizer --batch_size 128 --square_image_max_size 224 --loss_function ctc --num_workers_train 16 --epoches 75 --learning_rate 0.0001 --reduce_on_plateau 5 --decoder_architecture transformer --output_model_name non_linear_latin_from_hiertext --load_checkpoint --checkpoint_name /data/users/amolina/oda_ocr_output/non_linear_hiertext_only_base/non_linear_hiertext_only_base.pt
CUDA_DEVICE_ORDER=PCI_BUS_ID CUDA_VISIBLE_DEVICES=2 python main.py  --use_mlt --mlt19_langs Chinese --model_architecture vit_atienza --image_height 224 --tokenizer_name oda_giga_tokenizer --batch_size 128 --square_image_max_size 224 --loss_function ctc --num_workers_train 16 --epoches 75 --learning_rate 0.0001 --reduce_on_plateau 5 --decoder_architecture transformer --output_model_name non_linear_chinese_from_hiertext --load_checkpoint --checkpoint_name /data/users/amolina/oda_ocr_output/non_linear_hiertext_only_base/non_linear_hiertext_only_base.pt
CUDA_DEVICE_ORDER=PCI_BUS_ID CUDA_VISIBLE_DEVICES=2 python main.py  --use_mlt --mlt19_langs Japanese --model_architecture vit_atienza --image_height 224 --tokenizer_name oda_giga_tokenizer --batch_size 128 --square_image_max_size 224 --loss_function ctc --num_workers_train 16 --epoches 75 --learning_rate 0.0001 --reduce_on_plateau 5 --decoder_architecture transformer --output_model_name non_linear_japanese_from_hiertext --load_checkpoint --checkpoint_name /data/users/amolina/oda_ocr_output/non_linear_hiertext_only_base/non_linear_hiertext_only_base.pt 
CUDA_DEVICE_ORDER=PCI_BUS_ID CUDA_VISIBLE_DEVICES=2 python main.py  --use_mlt --mlt19_langs Bangla --model_architecture vit_atienza --image_height 224 --tokenizer_name oda_giga_tokenizer --batch_size 128 --square_image_max_size 224 --loss_function ctc --num_workers_train 16 --epoches 75  --learning_rate 0.0001 --reduce_on_plateau 5 --decoder_architecture transformer --output_model_name non_linear_bangla_from_hiertext --load_checkpoint --checkpoint_name /data/users/amolina/oda_ocr_output/non_linear_hiertext_only_base/non_linear_hiertext_only_base.pt
CUDA_DEVICE_ORDER=PCI_BUS_ID CUDA_VISIBLE_DEVICES=2 python main.py  --use_mlt --mlt19_langs Hindi --model_architecture vit_atienza --image_height 224 --tokenizer_name oda_giga_tokenizer --batch_size 128 --square_image_max_size 224 --loss_function ctc --num_workers_train 16 --epoches 75 --learning_rate 0.0001 --reduce_on_plateau 5 --decoder_architecture transformer --output_model_name non_linear_hindi_from_hiertext --load_checkpoint --checkpoint_name /data/users/amolina/oda_ocr_output/non_linear_hiertext_only_base/non_linear_hiertext_only_base.pt
CUDA_DEVICE_ORDER=PCI_BUS_ID CUDA_VISIBLE_DEVICES=2 python main.py  --use_mlt --mlt19_langs Symbols --model_architecture vit_atienza --image_height 224 --tokenizer_name oda_giga_tokenizer --batch_size 128 --square_image_max_size 224 --loss_function ctc --num_workers_train 16 --epoches 75 --learning_rate 0.0001 --reduce_on_plateau 5 --decoder_architecture transformer --output_model_name non_linear_symbols_from_hiertext --load_checkpoint --checkpoint_name /data/users/amolina/oda_ocr_output/non_linear_hiertext_only_base/non_linear_hiertext_only_base.pt


CUDA_DEVICE_ORDER=PCI_BUS_ID CUDA_VISIBLE_DEVICES=2 python main.py  --use_mlt --mlt19_langs Korean --model_architecture vit_atienza --image_height 224 --tokenizer_name oda_giga_tokenizer --batch_size 128 --square_image_max_size 224 --loss_function ctc --num_workers_train 16 --epoches 75 --learning_rate 0.0001 --reduce_on_plateau 5 --decoder_architecture transformer --linear_model --output_model_name taylor_linear_korean_from_hiertext --load_checkpoint --checkpoint_name /data/users/amolina/oda_ocr_output/non_linear_hiertext_only_base/non_linear_hiertext_only_base.pt
CUDA_DEVICE_ORDER=PCI_BUS_ID CUDA_VISIBLE_DEVICES=2 python main.py  --use_mlt --mlt19_langs Arabic --model_architecture vit_atienza --image_height 224 --tokenizer_name oda_giga_tokenizer --batch_size 128 --square_image_max_size 224 --loss_function ctc --num_workers_train 16 --epoches 75 --learning_rate 0.0001 --reduce_on_plateau 5 --decoder_architecture transformer --linear_model --output_model_name taylor_linear_arabic_from_hiertext --load_checkpoint --checkpoint_name /data/users/amolina/oda_ocr_output/non_linear_hiertext_only_base/non_linear_hiertext_only_base.pt
CUDA_DEVICE_ORDER=PCI_BUS_ID CUDA_VISIBLE_DEVICES=2 python main.py  --use_mlt --mlt19_langs Latin --model_architecture vit_atienza --image_height 224 --tokenizer_name oda_giga_tokenizer --batch_size 128 --square_image_max_size 224 --loss_function ctc --num_workers_train 16 --epoches 75 --learning_rate 0.0001 --reduce_on_plateau 5 --decoder_architecture transformer --linear_model --output_model_name taylor_linear_latin_from_hiertext --load_checkpoint --checkpoint_name /data/users/amolina/oda_ocr_output/non_linear_hiertext_only_base/non_linear_hiertext_only_base.pt
CUDA_DEVICE_ORDER=PCI_BUS_ID CUDA_VISIBLE_DEVICES=2 python main.py  --use_mlt --mlt19_langs Chinese --model_architecture vit_atienza --image_height 224 --tokenizer_name oda_giga_tokenizer --batch_size 128 --square_image_max_size 224 --loss_function ctc --num_workers_train 16 --epoches 75 --learning_rate 0.0001 --reduce_on_plateau 5 --decoder_architecture transformer --linear_model --output_model_name taylor_linear_chinese_from_hiertext --load_checkpoint --checkpoint_name /data/users/amolina/oda_ocr_output/non_linear_hiertext_only_base/non_linear_hiertext_only_base.pt
CUDA_DEVICE_ORDER=PCI_BUS_ID CUDA_VISIBLE_DEVICES=2 python main.py  --use_mlt --mlt19_langs Japanese --model_architecture vit_atienza --image_height 224 --tokenizer_name oda_giga_tokenizer --batch_size 128 --square_image_max_size 224 --loss_function ctc --num_workers_train 16 --epoches 75 --learning_rate 0.0001 --reduce_on_plateau 5 --decoder_architecture transformer --linear_model --output_model_name taylor_linear_japanese_from_hiertext --load_checkpoint --checkpoint_name /data/users/amolina/oda_ocr_output/non_linear_hiertext_only_base/non_linear_hiertext_only_base.pt 
CUDA_DEVICE_ORDER=PCI_BUS_ID CUDA_VISIBLE_DEVICES=2 python main.py  --use_mlt --mlt19_langs Bangla --model_architecture vit_atienza --image_height 224 --tokenizer_name oda_giga_tokenizer --batch_size 128 --square_image_max_size 224 --loss_function ctc --num_workers_train 16 --epoches 75  --learning_rate 0.0001 --reduce_on_plateau 5 --decoder_architecture transformer --linear_model --output_model_name taylor_linear_bangla_from_hiertext --load_checkpoint --checkpoint_name /data/users/amolina/oda_ocr_output/non_linear_hiertext_only_base/non_linear_hiertext_only_base.pt
CUDA_DEVICE_ORDER=PCI_BUS_ID CUDA_VISIBLE_DEVICES=2 python main.py  --use_mlt --mlt19_langs Hindi --model_architecture vit_atienza --image_height 224 --tokenizer_name oda_giga_tokenizer --batch_size 128 --square_image_max_size 224 --loss_function ctc --num_workers_train 16 --epoches 75 --learning_rate 0.0001 --reduce_on_plateau 5 --decoder_architecture transformer --linear_model --output_model_name taylor_linear_hindi_from_hiertext --load_checkpoint --checkpoint_name /data/users/amolina/oda_ocr_output/non_linear_hiertext_only_base/non_linear_hiertext_only_base.pt
CUDA_DEVICE_ORDER=PCI_BUS_ID CUDA_VISIBLE_DEVICES=2 python main.py  --use_mlt --mlt19_langs Symbols --model_architecture vit_atienza --image_height 224 --tokenizer_name oda_giga_tokenizer --batch_size 128 --square_image_max_size 224 --loss_function ctc --num_workers_train 16 --epoches 75 --learning_rate 0.0001 --reduce_on_plateau 5 --decoder_architecture transformer --output_model_name taylor_linear_symbols_from_hiertext --load_checkpoint --checkpoint_name /data/users/amolina/oda_ocr_output/non_linear_hiertext_only_base/non_linear_hiertext_only_base.pt --linear_model
